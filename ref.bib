
@article{Forman,
	abstract = {In the realm of machine learning for text classification, TF{\textperiodcentered}IDF is the most widely used representation for real-valued feature vectors. However, IDF is oblivious to the training class labels and naturally scales some features inappropriately. We replace IDF with Bi-Normal Separation (BNS), which has been previously found to be excellent at ranking words for feature selection filtering. Empirical evaluation on a benchmark of 237 binary text classification tasks shows substantially better accuracy and F-measure for a Support Vector Machine (SVM) by using BNS scaling. A wide variety of other feature representations were later tested and found inferior, as well as binary features with no scaling. Moreover, BNS scaling yielded better performance without feature selection, obviating the need for feature selection.},
	author = {Forman, George},
	file = {:home/jtbai/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forman - Unknown - BNS Feature Scaling An Improved Representation over TF{\textperiodcentered}IDF for SVM Text Classification.pdf:pdf},
	keywords = {Design methodology,Experimentation Keywords Text classification,I52 [Pattern Recognition],Information filtering,Performance,Support Vector Machine,TF*IDF text representation,feature selection,feature weighting,machine learning},
	mendeley-groups = {BNS,Essay},
	title = {{BNS Feature Scaling: An Improved Representation over TF{\textperiodcentered}IDF for SVM Text Classification}},
	url = {http://delivery.acm.org.acces.bibl.ulaval.ca/10.1145/1460000/1458119/p263-forman.pdf?ip=132.203.227.63{\&}id=1458119{\&}acc=ACTIVE SERVICE{\&}key=FD0067F557510FFB.145D743BD1083546.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}{\_}{\_}acm{\_}{\_}=1528149959{\_}1f01fd3973347bde4b30898a2943b30},
	year = {2008}
}

	@inproceedings{Francis2006,
	abstract = {MOTIVATION. One of the newest areas of data mining is text mining.$\backslash$nText mining is used to extract information from free form text data$\backslash$nsuch as that in claim description fields. This paper introduces the$\backslash$nmethods used to do text mining and applies the method to a simple$\backslash$nexample. $\backslash$n$\backslash$nMETHOD. The paper will describe the methods used to parse data into$\backslash$nvectors of terms for analysis. It will then show how information$\backslash$nextracted from the vectorized data can be used to create new features$\backslash$nfor use in analysis. focus will be placed on the method of clustering$\backslash$nfor finding patterns in unstructured text information.$\backslash$n$\backslash$nRESULTS. The paper shows how feature variables can be created from$\backslash$nunstructured text information and used for prediction.$\backslash$n$\backslash$nCONCLUSIONS. Text mining has significant potential to expand the$\backslash$namount of information that is available to insurance analysts for$\backslash$nexploring and modeling data.$\backslash$n$\backslash$nAVAILABILITY. Free software that can be used to perform some of the$\backslash$nanalyses describes in this paper is described in the appendix.},
	author = {Francis, Louise A},
	booktitle = {Casualty Actuarial Society Forum},
	file = {:home/jtbai/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Francis - Unknown - Taming Text An Introduction to Text Mining.pdf:pdf},
	isbn = {3540329609},
	keywords = {data mining,predictive modeling,statistical analysis,text mining},
	mendeley-groups = {Essay},
	pages = {51--88},
	title = {{Taming Text: An Introduction to Text Mining}},
	url = {https://www.casact.org/pubs/forum/06wforum/06w55.pdf http://www.casact.net/pubs/forum/06wforum/06w55.pdf},
	year = {2006}
}

@book{hastie2013elements,
	title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
	author={Hastie, T. and Tibshirani, R. and Friedman, J.},
	isbn={9780387216065},
	lccn={2001031433},
	series={Springer Series in Statistics},
	url={https://books.google.ca/books?id=yPfZBwAAQBAJ},
	year={2013},
	publisher={Springer New York}
}

@book{jurafsky2009speech,
	title={Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition},
	author={Jurafsky, Dan and Martin, James H},
	journal={Prentice Hall series in artificial intelligence},
	pages={1--1024},
	year={2009},
	publisher={Prentice Hall, Pearson Education International}
}

@inproceedings{francis2010text,
	title={Text mining handbook},
	author={Francis, Louise and Flynn, Matt},
	booktitle={Casualty Actuarial Society E-Forum},
	pages={1},
	year={2010}
}